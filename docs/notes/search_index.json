[
["index.html", "Introdução à jurimetria com o R Prefácio", " Introdução à jurimetria com o R José de Jesus Filho Última atualização: 12/mai/2019 Prefácio A principal motivação em escrever este livro tem sido incentivar estudantes de direito a realizar pesquisas empíricas quantitativas. A psicologia desenvolveu a psicometria e a economia desenvolveu a econometria, cada uma com objeto e métodos próprios. Cabe ao jurista assumir a tarefa de desenvolver métodos quantitativos próprios para análise da prática do direito, seja nas cortes, nos escritórios de advocacia, nos departamentos jurídicos das empresas ou ongs e mesmo do direito achado na rua. Minha expectativa é a de que, não somente as faculdades de direito criem as respectivas cadeiras de jurimetria, mas também as escolas da magistratura, do Ministério Público, da Defensoria Pública e das procuradorias dos estados, incorporem a jurimetria como parte da formação de seus profissionais. Até pouco mais de dez anos, a jurimetria, enquanto campo específico de estudo, era praticamente desconhecida. Foi o trabalho pioneiro do professor Marcelo Guedes Nunes, ao defender em 2012 sua tese de doutorado sobre o tema e criar a Associação Brasileira de Jurimetria, que esta disciplina ganhou fôlego a passou a ser disseminada. Convenções neste livro Itálico novos termos, nomes, botões e similares. Texto com largura constante geralmente usado em parágrafos para indicar o código R. Isso inclui comandos, variáveis, funções, tipos de dados, bases e nomes de arquivos. Texto com largura constante em fundo cinza indica R código que foi digitado literalmente por você. Pode parecer em parágrafos para melhor distinção entre códigos executáveis e e não executáveis, mas será encontrado principalmente em forma de blocos largos de códig R. Esses blocos são referidos como trechos de códigos (code chunks). Agradecimentos Devo muito à minha esposa Melissa, não somente pelo constante incentivo, mas também pelos frequentes conselhos sobre como conduzir o meu trabalho. Aos colegas da Associação Brasileira de Jurimetria (ABJ), especialmente ao Julio Trecenti, por haver me introduzido à jurimetria e, com isso, resgatar a minha paixão adolescente por exatas a fim de aplicá-la ao direito. Os professores Marcos e Lorena Barbiera me iniciaram no mundo dos métodos quantitativos. A eles um especial agradecimento. O ambiente colaborativo da comunidade do R foi terra fecunda onde plantei as sementes que hoje geram este e tantos outros frutos open source. This book is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],
["introducao.html", "Introdução", " Introdução Este livro está voltado ao estudante de direito de graduação ou pós-graduação. Ele não pressupõe conhecimento prévio de métodos quantitativos e conhecimento de matemática que vá além do aprendido no ensino médio. O objetivo é introduzir ao estudante a metodologia quantitativa e é proeminentemente conceitual. Demonstrações de teoremas e derivações matemáticas, quando existirem, serão incluídas nos apêndices. Pretendemos que esta seja uma leve introdução aos métodos quantitativos de pesquisa empírica no direito. Mas isso não significa que flexibilizaremos o rigor na explanação dos conceitos em favor da didática. Um cuidado especial será tomado para conciliar essas duas exigências. Além de ser uma obra voltada a estudantes de direito, o livro possui alguns diferenciais em relação ao que tem sido produzido até o momento. Passo a apontá-los. Primeiramente, ao contrário da maioria das obras jurídicas este livro, em sua versão eletrônica, é inteiramente gratuito, disponibilizado via web, com passibilidade de ser baixado para versões epub ou pdf, igualmente gratuitas. Todos as situações reais apresentadas serão provenientes da experiência do autor no âmbito do direito, seja de suas pesquisas, seja de pessoas por ele auxiliadas no mestrado ou no doutorado. O livro não somente oferece os tópicos típicos de introdução à métodos quantitativos, mas inclui também alguns tópicos de processamento de linguagem natural, os quais permitem ao pesquisador analisar dados não estruturados, como decisões judiciais, petições e pareceres técnicos. O terceiro diferencial deste livro é que ele ensina a programar em R, ou seja, o estudante irá não somente aprender as técnicas de métodos quantitativos, como também irá colocá-las em prática enquanto estuda. Poderá testar o aprendizado no âmbito do próprio livro e saber se acertou ou errou no mesmo momento. O livro foi organizado a partir da experiência do autor como pesquisador, como professor e orientador de estudantes de direito. Metodologia nunca foi um assunto adequadamente tratado nos cursos de direito. Na maioria das faculdades, a disciplina reduz-se a ensinar o passo a passo da redação do trabalho de conclusão de curso. Metodologia tem sido mais bem um curso sobre como redigir o trabalho de conclusão de curso do que propriamente familiarizar os alunos com ferramentas para a pesquisa empírica ou mesmo teórica. Consequência disso é que muitos partem para o mestrado com questões relevantes a serem pesquisadas, mas sem noção alguma de como converter suas questões em hipóteses teóricas e operacionalizá-las em variáveis concretas. Muitos terminam por reduzir seu trabalho à discussão hermenêutica, ou quando se arriscam a levantar dados quantitativos, apresentam os resultados sem qualquer rigor metodológico ou, o que é pior, vão a campo, coletam dados e tentam identificar possíveis correlações ou associações. A partir desses dilemas, a proposta do presente livro é instrumentalizar o pesquisador do direito para conduzir pesquisas válidas, confiáveis, reproduzíveis, replicáveis e robustas. Para tanto, o livro seguirá o seguinte roteiro. Inicialmente trataremos do desenho de pesquisa, ou seja, como passar do problema da pesquisa para a construção de uma teoria causal, da elaboração de hipóteses teóricas que expliquem as relações entre causa e efeito, da operacionalização dessas hipóteses teóricas em variáveis concretas as quais possam medir o quanto um fator influencia o resultado. Uma decisão, ainda que provisória, seria eleger o modelo estatístico utilizado para testar as hipóteses declaradas, mas essa tarefa será colocada mais adiante, quando adentrarmos nos métodos quantitativos propriamente ditos. Em seguida, passaremos a trabalhar com os objetos a serem medidos e sua categorização. A pergunta-guia dessa parte será: O que o pesquisador do direito pode medir e como fazê-lo? Aprenderemos sobre os níveis de mensuração e suas escalas. Há valores que são categóricos, tais como mulher e homem ou religião: cristão, judeu, mulçumano. Há valores que são contáveis, tais como o número de juízes de um Tribunal de Justiça, o número de processos julgados no mês, o número de processos distribuídos. Há valores que são contínuos, por exemplo, os salários dos juízes, promotores e defensores, o tempo de provimento na carreira e assim por diante. A seção anterior servirá de base para introduzir o estadante ao ambiente de programação R, a fim de familizarizá-lo com a interação com a máquina por meio da emissão de comandos em vez de interface gráfica. O passo seguinte será aplicar o aprendido até aqui para criar um projeto de pesquisa no próprio ambiente R. O estudante conhecerá ferramentas úteis para organizar seu projeto de pesquisa, de forma a integrar texto, código e dados num só ambiente e criar mecanismos de controle e validação da pesquisa. Os próximos capítulos serão dedicados à coleta, importação, limpeza, transformação e disposição dos dados para análise. Alêm das lições, o estudante terá oportunidade de praticar dezenas de exercícios, a fim de solidificar seu aprendizado em R. Aprenderá também como criar gráficos a fim de visualizar a distribuição dos dados. Métodos de análise descritiva e exploratória dos dados serão introduzidos a fim de explorar eficazmente as relações entre as variáveis explicativas e a variável resposta. Os capítulos seguintes serão devotados a introduzir o estudante os modelos estatísticos mais comuns de análise de dados, tais como modelos lineares, modelos lineares generalizados, séries temporais, modelos mistos e modelos com dados em painel. "],
["1-pq.html", "Capítulo 1 Pesquisa quantitativa", " Capítulo 1 Pesquisa quantitativa A pesquisa quantitativa em direito pressupõe a realização de quatro fases. A primeira delas concerne ao planejamento, isto é, "],
["1-1-problemas-do-mundo-real.html", "1.1 Problemas do mundo real", " 1.1 Problemas do mundo real Suponha que você foi contratado por um familiar de alguém que foi preso há dois dias em flagrante delito sob suspeita de ter praticado tráfico de drogas. Os autos de inquérito policial foram distribuídos para a vara n O flagrante foi convertido em prisão preventiva,1. Você toma conhecimento de que na vara em que tramita o processo foram julgados 754 pedidos de liberdade provisória em casos similares ao seu no último ano.2 Desses, 420 foram julgados favoravelmente ao pedido de liberdade provisória. Você faz as contas e verifica que 0,56, ou 56%, dos pedidos foram concedidos, isto é, a maioria. Suponho que você deve ter se perguntado: Aquela vara realmente tende a conceder mais pedidos de liberdade provisória do que negar? Esta proporção é suficiente para você dizer aos familiares que está confiante de que o juiz irá conceder a liberdade provisória? Suponha agora que você expandiu o período e elevou o número de casos para 2500, fez os cálculos e chegou a uma proporção não muito distante da primeira, agora 0,57. Os valores são similares, mas intuitivamente a informação é melhor, pois baseada em um maior número de casos. O quão distante o risco relativo de 0,57, que chamaremos de parâmetro de interesse \\(\\theta\\), para concessão está de 1? A resposta a esta questão requer a formulação de um modelo estocátisco que descreva os dados observados. A análise estatística lhe ajuda a passar dos dados observados para realizar declarações acerca do parâmetro de interesse \\(\\theta\\). Como você deve ter observado, a incerteza permeia o mundo dos fatos e das relações. Se estou prestando concurso público para ser promotor, defensor, juiz ou oficial de justiça, diante da minha nota, quais as minhas chances de ser aprovado e ser convocado? A jurimetria é o único ramo do direito que se dedica a medir a incerteza diante da limitação de informação disponível. Seu objetivo não é eliminar a incerteza, mas quantificá-la. Com efeito, a incerteza permanecerá mesmo depois de conduzida a análise. Tecnicamente não há conversão de flagrante em prisão, mas sim uma apreciação pelo juiz sobre a presença dos requisitos da prisão preventiva↩ Quando falamos de similares, estamos considerando que foram controlados os demais fatores: reincidência, quantidade de droga, tipo de droga, promotor etc↩ "],
["1-2-duas-incertezas.html", "1.2 Duas incertezas", " 1.2 Duas incertezas A incerteza de que falávamos acima e a qual a jurimetria, por meio de métodos matemáticos, é capaz de medir, é chamada de incerteza estocástica ou aleatória e disso trataremos quando falarmos de análise dos resíduos. Há porém uma outra incerteza por vezes chamada de incerteza indutiva que a estatítica sozinha não pode resolver, mas a junção de esforços entre o estatístico e a jurista experiente pode reduzi-la significativamente. Questões como: Fizemos a pergunta correta? Conhecemos bem a realidade na qual estamos trabalhando? "],
["1-3-dedutiva-ou-indutiva.html", "1.3 Dedutiva ou indutiva?", " 1.3 Dedutiva ou indutiva? Frequentemente estudantes me perguntam se a jurimetria é indutiva ou dedutiva. A depender da aspecto levado em consideração, ela pode se apresentar como dedutiva ou como indutiva. Ao desenvolver o modelo matemático para lidar com o aspecto aleatório dos eventos, ela não carece de argumentos e, nesse aspecto é dedutiva. Por outro lado, ao observar os fatos e a partir deles realizar inferências, percorre-se um processo indutivo e daí surge o problema de separar o estocástico do sistemático. O pesquisador se engaja no esforço por identificar uma relação determinística de causa efeito, mas está sempre às voltas com aspectos aleatórios. Mesmo que você não venha a aplicar métodos quantitativos nas suas pesquisas, aprender estatística é fundamental por vários motivos: 1 - Nós estamos circunvizinhados por números. As notícias veiculadas na mídia divulgam dados diariamente. Saber ler criticamente esses dados torna-nos menos suscetíveis a manipulações. 2 - "],
["1-4-o-problema-de-pesquisa.html", "1.4 O problema de pesquisa", " 1.4 O problema de pesquisa "],
["causalidade.html", "Causalidade", " Causalidade 1.4.1 Causalidade na pesquisa quanti e na pesquisa quali. 1.4.2 "],
["introducao-ao-r.html", "Introdução ao R", " Introdução ao R Na introdução à estatística, vimos os vários níveis de mensuração, isto é, variáveis podem ser discretas ou contínuas. Algo que não vimos, mas que iremos trabalhar estensamente durante o curso será objetos guardados como texto. Trabalharemos com o manuseio de texto em vários capítulos. Por ora, a menção serve apenas para introduzir como esses vários níveis e tipos de informação são representados no R. Ao final desse capítulo, você deverá ser capaz de operar com as seguintes estruturas: Funções no R e seus argumentos Objetos no R Tipos básicos do R Pacotes no R "],
["1-5-funcoes-no-r.html", "1.5 Funções no R", " 1.5 Funções no R O R opera por meio da chamada de funções. Por exemplo, para calcular a raiz quadrada de um número, você usa a função sqrd: sqrd(4) Está função irá produzir o número dois no console do R. É assim que opera a maioria das funções no R. Se você associar o resultado a um nome, em vez de mostrar o resultado no console, esta função irá alojar o resultado no nome que você der. Para ver o resultado, você deve imprimi-lo no console, usando a função print ou simplesmente digitando o objeto: a &lt;- sqrd(9) print(a) Se você chamar a função sem os parênteses, o R irá mostrar o código utilizado quando você chama a função: factorial Então, para chamar uma função, você sempre deve utilizar parênteses. Dentro deles, você deve colocar os argumentos da função. Veremos isso em pormenor no próximo tópico. Se você quer saber para que serve e como opera uma função, você deve colocar o símbolo de interrogação antes da função, sem necessidade de incluir os parênteses: ?sqrt "],
["1-6-argumentos.html", "1.6 Argumentos", " 1.6 Argumentos As entradas que você coloca dentro dos parênteses são chamadas de argumentos. Algumas funções não requerem argumento, por exemplo, se você quer imprimir a data de hoje no console, basta usar a função Sys.Date() sem nenhum argumento: Sys.Date() Outras funções requerem somente um argumento. No exemplo a seguir, a função abs irá calcular o valor absoluto do número fornecido: abs(-5) Outras funções requerem múltiplos argumentos. Por exemplo, a função rep (replicar) recebe apenas um argumento, mas faz mais sentido fornecer ao menos um segundo argumento, indicando quantas vezes quero replicar o primeiro. Do contrário, ela subentende que você apenas uma replicação e retorna esta única. # Irá replicar o número quatro cinco vezes. rep(4,5) Você deve ter notado que eu coloquei a cerquilha (#), também conhecida como “jogo da velha” ou “tralha” no Brasil e “cardinal” em Portugal, antes de uma expressão. A # no R indica que o que vem imediatamente após ela não será avaliado, ou seja, o R irá ignorar as linhas iniciadas por #, mesmo que você coloque uma função. "],
["2-metodologia.html", "Capítulo 2 Metodologia ", " Capítulo 2 Metodologia "],
["2-1-hipotese.html", "2.1 Hipótese", " 2.1 Hipótese O presente texto apresenta metodologia aplicada para a pesquisa jurispruencial no âmbito do Supremo Tribunal Federal sobre os pedidos de reclamação contra controle concentrado. A metodologia é eminentemente quantitativa e visou oferecer uma explicação das decisões judiciais da Suprema Corte diante do instituto processual da reclamação. A pesquisa está particularmente interessada em saber se as cortes inferiores se contrapôem sistematicamente às decisões do STF e conhecer se houve impacto da alteração legislativa, especificamente a promovida no Código de Processo Civil de 2015, na quantidade de decisões judiciais prolatadas pelos órgãos julgadores do STF, sejam eles singulares ou colegiados. Hipótese 1: A pesquisa buscou testar duas hipóteses. A primeira delas foi verificar se há um descumprimento significativo, por parte dos juízes das cortes inferiores, das decisões do STF. Hipótese 2: A segunda hipótese era saber se com a alteração do CPC promovida em 2015, ao ampliar as hipóteses de cabimento de reclamação, houve alteração no comportamento dos ministros do STF no sentido de aumentar o número. "],
["2-2-operacionalizacao.html", "2.2 Operacionalização", " 2.2 Operacionalização Com o fim de verificar as duas hipóteses acima referidas, passamos à sua operacionalização, isto é, passar da da formulação geral sobre comportamento judicial com respeito às reclamações levadas ao STF, para declarações mais específicas, utilizando-se de variáveis mensuráveis e hipotetizar sobre a relação entre elas(???). A partir da revisão bibligráfica realizada e da consulta jurisprudencial, concluímos é possível testar a primeira hipótese se observarmos que todos ou alguns segmentos do Judiciário têm suas decisões repetidamente cassadas pelo STF em virtude da mesma matéria. Se um ou mais segmentos do Judiciário regularmente tem suas decisões cassadas porque feriram um dos paradigmas do STF, é possível afirmar que é significante esse descumprimento. Por outro lado, se o STF julga constantemente improcedente as reclamações, há aqui uma sugestão de que o problema não se encontra no Judiciário, mas no uso inapropriado da reclamação. Quanto à segunda hipótese, é possível testá-la a partir da comparação da quantidade de provimentos antes e depois da alteração do CPC de 2015. Se o número de provimentos aumentou significativamente com a mudança do CPC, temos uma indicação de que houve efeito da alteração no comportamento da Suprema Corte. Do contrário, se não houve diferença alguma, se o número de decisões procedentes caiu ou se aumentou muito pouco, devemos descartar tal hipótese de que o CPC 2015 gerou algum efeito em termos de concessões de reclamações. Acontece que apenas comparar as decisões favoráveis ou desfavoráveis com o segmento do Judiciário e com o paradigma supostamente violado não é suficiente para alcançarmos uma conclusão confiável. Isto porque o direto aplicado está dentro do campo das ciências sociais, as quais lidam com dados observacionais e não com dados experimentais como ocorre com as pesquisas na área de saúde(Silva 2018). Com dados experimentais o pesquisador possui controle preciso sobre os fatores que causam ou modificam o resultado obtido. Por exemplo, para testar a eficácia de uma vacina, o pesquisador de saúde irá dividir aleatoriamente dois grupos, um que receberá a vacina, o outro que não receberá, chamado grupo de controle. Para testar sua hipótese, é suficiente ele aplicar um teste de associação simples e verificar se as diferenças são significativas ou não(Silva 2018). Por sua vez, as pesquisas em ciências sociais se caracterizam por serem observacionais e a pesquisadora não possui controle apriorístico sobre o efeito de uma variável sobre a outra. Ela deve considerar outros fatores que afetam o resultado para assim isolar o efeito de cada uma das variáveis explicativas sobre o resultado(Silva 2018). Na pesquisa em tela, estamos diante de dados observacionais. O esforço é dirigido em identificar todos os possíveis fatores que influenciam a resposta judicial ao pedido. Nesse sentido, os testes de associação bivariados são inadequados porque irão superdimensionar o efeito de uma variável sobre a outra. A tarefa será de isolar o efeito de cada uma das variáveis explicativas sobre a variável resposta: decisão judicial. Com efeito, podemos supor que o ministro A julgará diferentemente o pedido de reclamação quando se tratar de uma alegada violação a uma súmula do STF do que quando se tratar de uma violação a uma decisão inter partes ou que uma reclamação contra decisão da justiça do trabalho tem maior probabilidade de ter uma resposta favorável quando o ministro é fulano do que quando este é beltrano. Esse tipo de controle somente é posssível realizar por meio das técnicas de regressão, pois o objetivo destas é justamente isolar o efeito de cada uma das variáveis sobre os resultado. Diante disso, a partir da revisão bibliográfica e da leitura de uma amostra das decisões sobre reclamação, foi possível formular um modelo explicativo das decisões judiciais do STF sobre reclamação tomando em conta o segmento do Judiciário alvo da reclamação, o paradigma supostamente violado, o CPC vigente, a matéria tratada, o órgão julgador, a classe processual do “recurso”, se reclamação ou agravo da reclamação e a instância: primeira, segunda ou superior. Todas essas variáveis supostamente têm algum efeito sobre o resultado, de modo que todas elas têm de ingressar na análise porque eventualmente o efeito das variáveis de interesse: segmento, paradigma e CPC vigente é também afetado pelas demais e o próprio resultado: procedente ou improcedente é possivelmente fruto da interação de algumas dessas variáveis. Sendo assim, o modelo explicativo formulado quer saber como variam as chances de um desfecho processual favorável ou desfavorável (variável resposta) ao reclamante tomando em conta as variáveis explicativas acima mencionadas. O quadro abaixo mostra como ficam as hipóteses operacionalizadas em variáveis concretas: References "],
["2-3-viabilidade.html", "2.3 Viabilidade", " 2.3 Viabilidade Antes de iniciar a pesquisa, realizamos o estudo de viabilidade da pesquisa. O estudo de viabilidade não garante o sucesso ou insucesso da pesquisa, mas reduz significativamente as chances de incorrer em erros e em investimentos desnecessários. Dentre as razões para proceder ao estudo de viabilidade, podemos mencionar a disponibilidade dos dados que se pretende coletar, a adequação dos instrumentos propostos para coletar e analisar tais dados, a correspondência entre os objetivos da pesquisa e os métodos de análise apresentados, a adequação entre os recursos humanos, materiais e financeiros envolvidos e os resultados que se busca alcançar. O estudo da viabilidade é realizado de maneira exploratória e manual. Entramos nos site e varificamos se os dados existem, se estão disponíveis, se há quantidade e variabilidade suficientes para proceder a uma análise quantitativa. Nesse estudo, verificamos inicialmente que a pesquisa jurisprudencial retornava um número muito inferior ao reportado no relatório anual do STF. Diante disso, consultamos a secretaria de informação e esta nos informou que a pesquisa jurisprudencial não retornava todas as decisões. Uma das razões era de que somente as decisões publicadas no Diário de Justiça eram indexadas. Diante disso, optou-se por baixar a lista de decisões proferidas pelo STF, tanto colegiadas quanto monocráticas dos ministros e da presidência, para posteriormente baixar os processos individualmente. "],
["2-4-processo-de-coleta-dos-dados.html", "2.4 Processo de coleta dos dados", " 2.4 Processo de coleta dos dados A fim de garantir a reproducibilidade da pesquisa, todo o processo de coleta e análise de dados foi realizado via scripts na linguagem de programação R(???). Scripts são uma sequência de comandos a serem executados pela máquina (computador). Assim, para a coleta dos dados, utilizamos técnicas de respagem de dados (webscraping). Foram montados netbots para baixar as listas anuais de decisões em excel e dessas listas foi possivel obter os números dos processos. Os arquivos em excel foram importados para o R e empilhados numa única tabela. Em seguida, filtramos a tabela para manter somente as decisões relativas à reclamação. Baixamos três grupos de listas, decisões colegiadas, monocráticas e da presidência. A tabela totalizou cerca de 24 mil reclamações distintas. Em seguida montamos os scripts para baixar as páginas htmls com as informações processuais. As páginas do STF são organizadas segundo oito abas: aba principal (detalhes), aba informações, aba partes, aba andamento, aba decisões, aba deslocamentos, aba petições, aba recursos, aba pautas. Cada uma dessas abas consiste em um documento html distinto e para baixá-las não é suficiente realizar apenas uma requisição, mas oito requisições. A primeiras elas (detalhes) obtêm além das informações do cabeçalho, também o número do incidente, isto é, uma indexação interna do STF, chamada incidente. Com esses incidentes podemos realizar novas requisições para extrair os dados das demais abas. Em outras palavras, foram necessárias cerca de 192 mil requisições para acessar todo o conteúdo das respectivas abas. "],
["2-5-leitura-dos-html-parseamento.html", "2.5 Leitura dos html (parseamento)", " 2.5 Leitura dos html (parseamento) Após baixar as páginas, montamos scripts para extrair os dados dos htmls e organizá-los em tabelas. Esses scripts foram montados e um subproduto da tese é justamento a criação de um conjunto de funções para automatizar o processo de coleta, leitura e organização dos dados do STF. "],
["2-6-organizacao-dos-dados-e-mineracao-dos-textos.html", "2.6 Organização dos dados e mineração dos textos", " 2.6 Organização dos dados e mineração dos textos A fim de deixar os dados prontos para análise, é necessário organizá-los e limpá-los, ou seja, excluir informações excessivas e converter as variáveis para o formato adequado, ou seja, números, caracteres, datas e fatores. Para extrair informações relevantes do texto, utilizamos técnicas de processamento de linguagem natural (NLP, na sigla em inglês), sendo a mais comum delas as expressões regulares ou regex. "],
["2-7-analise.html", "2.7 Análise", " 2.7 Análise A análise será realizada considerando as duas hipóteses levantadas. A primeira delas busca responder se há um descumprimento sistemático por parte das cortes inferiores das decisões do STF. Para testar essa hipótese, utilizaremos regressão logística binária com dados em painel, tomando como efeitos fixos as seguintes variáveis tibble::tibble(explicativa=c(&quot;seguimento&quot;,&quot;paradigma&quot;,&quot;reclamante&quot;,&quot;autoridade reclamada&quot;,&quot;cpc15&quot;,&quot;orgao julgador&quot;), categorias=c(&quot;Superior Tribunal de Justiça,\\n Justiça Federal,\\n Justiça do Trabalho,\\n Justiça Eleitoral,\\n Justiça Militar da União,\\n Justiça dos Estados e do Distrito Federal e Territórios,\\n Justiça Militar Estadual&quot;, &quot;Decisão erga omnes,\\n decisão interpartes\\n súmula vinculante&quot;, &quot;pessoa física,\\n pessoa jurídica de direito privado,\\n pessoa jurídica de direito público&quot;, &quot;juiz de primeira instância,\\n juiz de segunda instância,\\n órgão colegiado&quot;, &quot;anterior, posterior&quot;, &quot;ministro,presidente,turma, pleno&quot; ) ) e como grupo ou efeito aleatório o órgão julgador. O modelo segue a seguinte equação: \\[ logit(y) = {\\beta}X + Zu + \\epsilon\\] que no R será modelado da seguinte forma: modelo &lt;- mle4::glmnet(decisao~seguimento+paradigma+reclamante+autoridade+cpc15+orgao_julgador+(1|orgao_julgador)) O modelo seguirá regressão logística binária com efeitos mistos. Segundo o qual, a decisão de procedência ou improcedência será estimada a partir das variáveis explicativas seguimento, paradigma, reclamante, autoridade, cpc15 e orgão julgador. O órgão julgador funcionará tanto como efeito fixo quanto como efeito aleatório. "],
["2-8-outros-modelos.html", "2.8 Outros modelos", " 2.8 Outros modelos Além de regressão logística, utilizaremos modelos de aprendizado de máquina (machine learning): floresta aleatória e boosting. "],
["2-9-analise-do-efeito-da-lei.html", "2.9 Análise do efeito da lei", " 2.9 Análise do efeito da lei Além desta análise, a pesquisa pretende avaliar o efeito sobre o comportamento judicial. A hipótese é de que com a ampliação de cabimento da reclamação, houve uma redução proporcional das decisões de mérito. Para tanto, iremos utilizar regressão descontínua, a fim de avaliar o efeito da lei sobre as decisões. A proposta é construir um framework para modelar o efeito de leis sobre as decisões judiciais e outros comportamentos. ``` "],
["3-obtencao-dos-dados.html", "Capítulo 3 Obtenção dos dados", " Capítulo 3 Obtenção dos dados O procedimento abaixo percorre o caminho para baixar, limpar e organizar as decisões do Supremo Tribunal Federal sobre a ação de reclamação. Para realizar este procedimento, utilizou-se um conjunto de rotinas de computador. Esse conjunto de rotinas foi criado dentro do ambiente de programação estatística R. A cada uma das rotinas é dado um nome. Esses nomes são agrupados no aplicativo conhecido como package (pacote de funções) de uma determinada linguagem de programação. A esse pacote também é dado um nome, que no caso se chama stf. Uma vez incorporadas num aplicativo, as rotinas, doravante chamadas de funções, podem ser facilmente reutilizadas, bastando chamá-las pelo nome e informar os argumentos para sua execução dentro de parênteses. A utilização do pacote stf confere replicabilidade e reprodutibilidade à pesquisa. As pesquisas científicas atuais, especialmente as quantitativas, caminham no sentido de garantir a reprodutibilidade, isto é, o caminho percorrido pelo pesquisador no processo de coleta, organização, exploração e análise dos dados, pode ser reproduzido por qualquer outra pesquisadora que tenha familiaridade com o programa utilizado. Reproducibilidade significa usar os mesmos dados e a mesma análise (códigos e modelos) e chegar aos mesmos resultados. Replicabilidade significa aproveitar o mesmo método (código e análise) para aplicá-los a novos dados. O R é um ambiente de programação com código aberto e gratuio. Igualmente, o pacote stf é de livre acesso. Para acessá-lo, basta clicar no seguinte link. Ali se encontram as orientações sobre como utilizá-lo. O pacote stf foi construído pensando em oferecer a acadêmicos de direito, de estatística e de ciência da computação, ferramentas para condução de suas análises sobre a atuação do Supremo Tribunal Federal. "],
["3-1-pacotes-necessarios.html", "3.1 Pacotes necessários", " 3.1 Pacotes necessários install.packages(c(&quot;devtools&quot;,&quot;tidyverse&quot;,&quot;janitor&quot;,&quot;quanteda&quot;)) devtools::install_github(&quot;jjesusfilho/stf&quot;) library(stf) library(tidyverse) library(janitor) "],
["3-2-baixar-o-acervo-do-stf.html", "3.2 Baixar o acervo do STF", " 3.2 Baixar o acervo do STF O acervo de decisões do STF é composto por três grupos de decisões: monocráticas, correspondentes às decisões individuais dos ministros; colegiadas, correspondentes às decisões das turmas e do pleno; presidente, correspondentes as decisões do presidente. A função seguinte irá baixar todo o acervo de decisões do STF correspondente aos anos indicados e o tipo de decisão. download_stf_collection(decision_type = &quot;monocraticas&quot;,years = 2011:2018,dir = &quot;monocraticas&quot;) download_stf_collection(decision_type = &quot;colegiadas&quot;,years = 2011:2018,dir = &quot;colegiadas&quot;) download_stf_collection(decision_type = &quot;presidente&quot;,years = 2011:2018,dir = &quot;presidente&quot;) "],
["3-3-ler-o-acervo.html", "3.3 Ler o acervo", " 3.3 Ler o acervo A função abaixo importa o acervo conforme a classe processual e os anos indicados. Esta função já faz o trabalho inicial de limpar a base de alguns elementos desnecessários e criar uma coluna chamada “incidente”, que é extraída do hyperlink. monocraticas &lt;- read_stf_collection(classes = &quot;Rcl&quot;,years = 2011:2018,dir = &quot;monocraticas&quot;) colegiadas &lt;- read_stf_collection(classes = &quot;Rcl&quot;,years = 2011:2018,dir = &quot;colegiadas&quot;) presidente &lt;- read_stf_collection(classes = &quot;Rcl&quot;,years = 2011:2018,dir = &quot;presidente&quot;) "],
["3-4-juncao-das-bases.html", "3.4 Junção das bases", " 3.4 Junção das bases Antes de seguir para os próximos passos, temos de juntar essas três bases e selecionar os processos únicos, de modo a reduzir o número de requisições de processos nos passos seguintes. acervo &lt;- bind_rows(monocraticas,colegiadas, presidente) numeros &lt;- unique(acervo$numero) Os números revelam que houve 22532 reclamações julgadas pelo Supremo Tribunal Federal entre janeiro de 2011 e dezembro de 2018. "],
["3-5-remover-colunas-nao-utilizadas.html", "3.5 Remover colunas não utilizadas", " 3.5 Remover colunas não utilizadas Para esta análise específica, somente algumas colunas são de interesse. O procedimento abaixo seleciona tais colunas. acervo &lt;- acervo %&gt;% select(classe,numero,data_autuacao,relator_atual,tipo_decisao,orgao_julgador,data_andamento) "],
["3-6-baixar-os-processos.html", "3.6 Baixar os processos", " 3.6 Baixar os processos A maneira mais rápida de baixar os processos seria por meio da coluna incidente. No entanto, notou-se que nem sempre o hiperlink, do qual é extraído o número do incidente, existe. Dessa forma, optou-se utilizar o número do processo na busca. A função abaixo realiza a busca no portal do STF. Tal busca poderá demorar bastante tempo porque são necessárias múltiplas requisições para cada um dos processos, correspondentes aos detalhes básicos que aparecem no topo das informações processuais e às oito abas. Esta função irá criar nove pastas dentro do diretório indicado, correspondentes às oito abas mais a pasta com os detalhes (metadados). Veja que para baixar esses arquivos, é necessário ter lido o acervo antes, pois utilizaremos as colunas classe e número para baixá-los. download_stf_dockets(classes = &quot;Rcl&quot;,docket_number = numeros) "],
["3-7-lendo-as-informacoes-processuais-.html", "3.7 Lendo as informações processuais.", " 3.7 Lendo as informações processuais. Das nove pastas, quatro delas são de especial interesse: detalhes, andamentos, partes e informações. Para a nossa análise, as demais são dispensáveis. detalhes &lt;- read_stf_details(path = &quot;detalhes&quot;, plan = &quot;multicore&quot;) andamentos &lt;- read_stf_docket_sheet(path = &quot;andamentos&quot;, plan = &quot;multicore&quot;) informacoes &lt;- read_stf_information(path = &quot;informacoes&quot;, plan = &quot;multicore&quot;) partes &lt;- read_stf_parties(path = &quot;partes&quot;, plan = &quot;multicore&quot;) "],
["4-transformacao.html", "Capítulo 4 Transformação ", " Capítulo 4 Transformação "],
["4-1-delimitacao-do-escopo.html", "4.1 Delimitação do escopo", " 4.1 Delimitação do escopo Na presente demonstração, iremos analisar as decisões de mérito do Supremo Tribunal Federal em casos com trânsito em julgado sobre pedidos de reclamação contra órgãos jurisdicionais entre os anos de 2011 e 2018, com exceção daquelas que versam sobre a competência do STF. Para realizar esse filtro, é necessária a utilização tanto de automação, vez que são mais de 22 mil processos, como também de métodos manuais, para aqueles casos em que a automação não for suficiente para extrair as informações relevantes. Sobre o uso de métodos automatizados de mineração e classificação de texto, observa-se que textos, nesse caso, decisões judiciais, são dados não estruturados. Com os avanços dos processos de automação na leitura e extração de dados, bem como, dos processos de classificação por meio do uso de inteligência artificial (deep learning), surgiram possibilidades de análise que antes não eram possíveis. No entanto, o uso de computação para ler e classificar textos está longe de atingir a qualidade do processo humano. Como bem afirmam (Grimmer and Stewart 2013), os métodos quantitativos de classificação de texto apenas ampliam a atividade humana, não a substituem. Além disso, não existe um método global de análise automatizada. Por fim, a classificação automatizada deve ser posteriormente validada por meio de revisão humana. A técnica adotada é tirar uma amostra de algumas dezenas de casos e submeter à leitura humana para verificar se houve erros e, em caso afirmativo, se o número é muito grande. References "],
["4-2-remocao-dos-casos-que-nao-serao-analisados-.html", "4.2 Remoção dos casos que não serão analisados.", " 4.2 Remoção dos casos que não serão analisados. Primeiramente iremos remover três grupos de casos. Aqueles que não transitaram em julgado no momento da análise, aqueles que correm em segredo de justiça e aqueles cujo reclamado não é órgão judicial. A informação sobre o trânsito em julgado se encontra no andamento. A informação sobre o segredo de justiça se encontra nos detalhes. transitado &lt;- andamentos %&gt;% filter(str_detect(titulo,&quot;(?i)transitado&quot;)) %&gt;% pull(&quot;incidente&quot;) %&gt;% unique() publico &lt;- detalhes %&gt;% filter(!str_detect(sigilo,&quot;Segredo de Justiça&quot;)) %&gt;% pull(&quot;incidente&quot;) %&gt;% unique() Para manter somente os casos em que o reclamado é órgão judicial, utilizaremos a função classify_respondent() do pacote stf . Além de excluir os casos em que o respondente não é órgão judicial, ela classifica o órgão judicial conforme a instância e o segmento do Poder Judiciário ao qual pertence. A classificação é bem sucedida na maioria dos casos, porém restaram algumas ambiguidades, relacionadas aos conselhos superiores dos tribunais de justiça, que ora decidem jurisdicionalmente, ora administrativamente. partes &lt;- stf::classify_respondent(partes) remover_conselhos &lt;- conselhos %&gt;% select(c(1,4,5)) %&gt;% slice(38:57) %&gt;% setNames(c(&quot;reclamados&quot;,&quot;incidente&quot;,&quot;acao&quot;)) %&gt;% filter(acao==&quot;EXCLUIR&quot;) remover_conselhos[2,1]&lt;-&quot;CONSELHO DA MAGISTRATURA DO TRIBUNAL DE JUSTIÇA DO ESTADO DO RIO GRANDE DO SUL&quot; partes &lt;- partes %&gt;% dplyr::filter(!is.element(incidente,remover_conselhos$incidente),!is.element(reclamado,remover_conselhos$reclamados)) partes &lt;- partes %&gt;% filter(instancia!=&quot;outros&quot;) %&gt;% filter(segmento!=&quot;outros&quot;) Por fim, verificamos que na base andamentos há movimentações que foram invalidadas. A função de leitura dos andamentos cria uma coluna indicando se a movimentação foi invalidada ou não. O que temos de fazer é simplesmente remover tais linhas da base andamentos. andamentos &lt;- andamentos %&gt;% filter(!invalido) "],
["4-3-baixar-textos-das-decisoes.html", "4.3 Baixar textos das decisões", " 4.3 Baixar textos das decisões Para baixar os textos das decisões, criamos duas funções, uma que baixa os textos em rtf, outra que baixa os textos em pdf. As urls dos textos estão contidas na base andamentos. Acontece que nem todos os textos se referem a decisões de mérito. Alguns são pareceres do Ministério Público, outros são meros despachos, outros são decisões interlocutórias ou apreciação de liminar ou cautelar. No entanto, a base andamento nem sempre é suficientemente informativa a respeito. Por essa razão, optamos por baixar todos os textos e, posteriormente, realizar as exclusões. dir.create(&quot;textos_rtf&quot;) dir.create(&quot;textos_pdf&quot;) stf::download_stf_pdf(andamentos,&quot;textos_pdf&quot;) stf::download_stf_rtf(andamentos,&quot;textos_rtf&quot;) textos_rtf &lt;- stf::read_stf_rtf(&quot;textos_rtf&quot;) textos_pdf &lt;- stf::read_stf_pdf(&quot;textos_pdf&quot;) texto &lt;- bind_rows(textos_rtf,textos_pdf) "],
["4-4-limpeza-dos-textos.html", "4.4 Limpeza dos textos", " 4.4 Limpeza dos textos Os textos das decisões são usados para identificar casos que devem ser excluídos. Por exemplo, processos em que não houve decisão de mérito, tais como decisões terminativas sem julgamento de mérito, processos extintos e prejudicados, seja por inércia da parte, seja por perda do objeto. Além disso, a decisão contida na base acervo nem sempre corresponde à real decisão sobre reclamação, pois os técnicos do STF simplesmente extraem a última decisão do andamento, a qual por vezes é um mero despacho. Igualmente, o título do andamento nem sempre são suficientemente descritivos. Alguns deles apenas indicavam que se tratatava de uma publicação no diário de justiça. Por essa razão, optou-se por extrair dos próprios textos a parte que corresponde à decisão, isto é, extraímos os últimos 800 caracteres do texto, que provavelmente contêm a decisão. Antes, porém, excluímos do texto as informações sobre quem assinou o documento. Ademais, cortamos essa parte a partir de palavras-chave tais como ex positis, diante do exposto etc. Com isso, foi possível verificar se a decisão se tratava de liminar ou cautelar, se era um mero despacho concedendo vista ou uma cerdidão. Algumas palavras no início do texto indicavam se ele era um parecer do MP, se era um embargo de declaração ou se era um agravo regimental. Quando não foi possível identificar no início, foi possível fazê-lo no final do texto. Alguns embargos foram convertidos em agravo regimental. A identificação desses casos também foi necessária. texto &lt;- texto %&gt;% unite(&quot;docname&quot;,extensao,docid,sep=&quot;&quot;) %&gt;% inner_join(andamentos,by=&quot;docname&quot;) texto &lt;- texto %&gt;% mutate(caracteres=nchar(texto)) texto &lt;- texto %&gt;% mutate(texto=str_remove_all(texto,&quot;(?i)documento assinado\\\\X+?(sob|por)\\\\s\\\\w+&quot;)) texto &lt;- texto %&gt;% mutate(texto = str_squish(texto)) texto &lt;- texto %&gt;% mutate(dispositivo = case_when( caracteres &gt; 800 ~{ stringi::stri_reverse(texto) %&gt;% stringi::stri_extract_first_regex(&quot;\\\\X{800}&quot;) %&gt;% stringi::stri_reverse() }, TRUE ~ texto)) texto &lt;- texto %&gt;% mutate(dispositivo=case_when( str_detect(texto1,&quot;(?i)(antes? o exposto|ex positis|diante disso|ante o quadro|pelo exposto|diante do exposto|nesse contexto|diante do contexto|por es[st]a razão|pelas razões expostas|por todo o exposto|dessa forma|decis.o:|com essas considerações|nessas condições|sendo assim|face ao exposto|do exposto)&quot;) ~{ str_extract(dispositivo,&quot;(?i)(antes? o exposto|ex positis|diante disso|ante o quadro|pelo exposto|diante do exposto|nesse contexto|diante do contexto|por es[ts]a razão|pelas razões expostas|por todo o exposto|dessa forma|decis.o:|com essas considerações|nessas condições|sendo assim|face ao exposto|do exposto).+&quot;) }, TRUE ~ dispositivo)) texto &lt;- texto %&gt;% filter(!str_detect(dispositivo,&quot;(?i)defiro a liminar&quot;)) texto &lt;- texto %&gt;% mutate(exclusoes = str_extract(texto,&quot;\\\\X{80}&quot;)) %&gt;% # filter(!str_detect(cautelar,&quot;MEDIDA CAUTELAR&quot;)) %&gt;% filter(!str_detect(exclusoes,&quot;(?i)(^Documento|^MINISTÉRIO|^procurador)&quot;)) %&gt;% filter(!str_detect(exclusoes,&quot;EMB.DECL.&quot;)) %&gt;% filter(!str_detect(doc,&quot;(?i)(PGR|despacho|certid.o|vista)&quot;)|is.na(doc)) %&gt;% select(-exclusoes) "],
["4-5-classificacao-dos-textos-conforme-procedencia-ou-improcedencia.html", "4.5 Classificação dos textos conforme procedência ou improcedência", " 4.5 Classificação dos textos conforme procedência ou improcedência O procedimento abaixo classifica os textos das decisões conforme procedência ou improcedência. O trabalho aqui foi recortar as decisões que eram de mérito. Para tanto, aplicamos a técnica de expressões regulares (regex) para identificar padrões nos textos dos dispositivos. Todo esse trabalho de identificação é heurístico e requer a conjunção de esforços de automação e validação pelo pesquisador. Uma técnica de processamento de linguagem natural muito útil é conhecida como “kwic” (key word in context). Por ela, buscamos uma palavra-chave, e.g., “procedente” em seu contexto, isto é, verificamos todas as vezes que esta palavra aparece no dispositivo e quais as palavras que a antecedem ou que a sucedem. Este procedimento permite observar padrões tais como “não procedente” ou “julgo procedente”. A experiência com classificações em outras pesquisas tem nos permitido reduzir significativamente as chances de erro. Mesmo quando ocorrem alguns erros, esses são mínimos e podem ser verificados por outros meios, tais como a verificação da consistência da base. Por exemplo, um texto erroneamente classificado como decisão de agravo deve ser contrastado com o tipo de decisão. Se esta foi uma decisão monocrática, claramente não se trata de um agravo. Por fim, uma particularidade do STF é o uso da expressão “nego seguimento” ora par indicar “improcedência”, ora para indicar uma decisão terminativa sem julgamento do mérito. Esse aspecto representou uma dificuldade a mais, pois foi necessário encontrar outras palavras que indicassem quando a expressão estava sendo usada para julgamento de mérito, e.g. “aderência” ou quando definitivamente não era de mérito, e.g, “súmula 734” ou “sucedâneo” e “atalho”. Diante da dúvida se a decisão era de mérito ou não, preferiu-se excluí-la. Ao final, depois de todas as exclusões e aplicações de filtros, chegou-se a 5636 casos. Uma amostra foi retirada para realização de validação humana. Não foi identificado nenhum erro. Isso não signfica que a base está isenta de erros de classificação, mas a pesquisadora está segura de que se estes ocorreram, eles foram mínimos e não afetarão significativamente os resultados. Ainda assim, a próxima etapa da análise, denominada “Exploratory Data Analysis” permite verificar inconsistências ou disparidades nas distribuições e anomalias nos dados. Novas correções são possíveis nesse momento. texto &lt;- texto %&gt;% dplyr::mutate(decisao = stringi::stri_trans_tolower(dispositivo), decisao = abjutils::rm_accent(decisao), decisao = case_when( str_detect(decisao,&quot;(nego|negado|negou)\\\\sseguimento&quot;) ~ &quot;nego seguimento&quot;, str_detect(decisao,&quot;(desprov\\\\w+|improv\\\\w+|improced\\\\w+)&quot;) ~ &quot;improvido&quot;, str_detect(decisao,&quot;(nao|nega\\\\w+)\\\\s+provi.*&quot;)~ &quot;improvido&quot;, str_detect(decisao,&quot;(rejeit\\\\w+|inadmitidos?)&quot;) ~ &quot;improvido&quot;, str_detect(decisao,&quot;mantiveram&quot;) ~ &quot;improvido&quot;, str_detect(decisao,&quot;(acolho|acolhido)&quot;) ~ &quot;provido&quot;, str_detect(decisao,&quot;(deram|da\\\\-*\\\\s*se|dando\\\\-*(se)*|comporta|dou|confere\\\\-se|se\\\\s*\\\\-*da|merece)\\\\sprovi\\\\w+&quot;) ~ &quot;provido&quot;, str_detect(decisao,&quot;parcial\\\\w*\\\\sprovimento&quot;) ~ &quot;provido&quot;, str_detect(decisao,&quot;(nao\\\\sderam|nao\\\\smerece|se\\\\snega|nega\\\\-*\\\\s*se|negar\\\\-*\\\\s*lhe|nao\\\\scomporta|negram|negararam|nego|negar|negou)&quot;) ~ &quot;improvido&quot;, str_detect(decisao,&quot;\\\\bprovimento&quot;) ~ &quot;provido&quot;, str_detect(decisao,&quot;\\\\bprocedente&quot;) ~ &quot;provido&quot;, str_detect(decisao,&quot;(nao\\\\sconhec\\\\w+|nao\\\\sse\\\\sconhec\\\\w+)&quot;) ~ &quot;não conhecido&quot;, str_detect(decisao,&quot;desconh\\\\w+&quot;) ~ &quot;desconhecido&quot;, str_detect(decisao,&quot;nao\\\\s+conhec\\\\w+&quot;) ~ &quot;desconhecido&quot;, str_detect(decisao,&quot;(homolog|desistencia)&quot;) ~ &quot;desistência&quot;, str_detect(decisao,&quot;diligencia&quot;) ~ &quot;conversão em diligência&quot;, str_detect(decisao,&quot;sobrest&quot;) ~ &quot;sobrestado&quot;, str_detect(decisao,&quot;prejudicad\\\\w*&quot;) ~ &quot;prejudicado&quot;, str_detect(decisao,&quot;(anular\\\\w*|nulo|nula|nulidade)&quot;) ~ &quot;anulado&quot;, TRUE ~ &quot;outros&quot;)) texto &lt;- texto %&gt;% mutate(decisao = case_when( decisao == &quot;provido&quot; ~ &quot;procedente&quot;, decisao == &quot;improvido&quot; ~ &quot;improcedente&quot;, TRUE ~ decisao )) improcedente &lt;- texto %&gt;% filter(decisao == &quot;improcedente&quot;) procedente &lt;- texto %&gt;% filter(decisao == &quot;procedente&quot;) seguimento &lt;- texto %&gt;% filter(decisao==&quot;nego seguimento&quot;) prejudicado&lt;-texto %&gt;% filter(decisao==&quot;prejudicado/extinto&quot;) sobrestado &lt;- texto %&gt;% filter(decisao==&quot;sobrestado&quot;) outros &lt;- texto %&gt;% filter(decisao==&quot;outros&quot;) sucedaneo &lt;- seguimento %&gt;% select(texto,docname) %&gt;% quanteda::corpus(&quot;docname&quot;,&quot;texto&quot;) %&gt;% quanteda::kwic(&quot;(?i)(suced[aâ]neo|\\\\bpresta\\\\b|atalho)&quot;,window = 20,valuetype = &quot;regex&quot;) %&gt;% as_tibble() sucedaneo&lt;-sucedaneo %&gt;% filter(keyword!=&quot;presta-se&quot;) %&gt;% pull(&quot;docname&quot;) %&gt;% unique() seguimento &lt;- seguimento %&gt;% filter(!docname %in% sucedaneo) sumula_734 &lt;- seguimento %&gt;% filter(str_detect(texto,&quot;\\\\b734\\\\b&quot;)) %&gt;% pull(&quot;docname&quot;) %&gt;% unique() seguimento &lt;- seguimento %&gt;% filter(!docname %in% sumula_734) aderencia &lt;- seguimento %&gt;% select(texto,docname) %&gt;% quanteda::corpus(&quot;docname&quot;,&quot;texto&quot;) %&gt;% quanteda::kwic(&quot;(?i)ader.ncia&quot;,window = 20,valuetype = &quot;regex&quot;) %&gt;% as_tibble() "],
["5-analise-exploratoria-de-dados.html", "Capítulo 5 Análise exploratória de dados", " Capítulo 5 Análise exploratória de dados Realizado o trabalho de coleta, limpeza e organização dos dados, a etapa seguinte é conduzir a análise exploratória de dados (EDA na sigla em inglês). A análise exploratória de dados visa dar a conhecer a estrutura subjacente dos dados e expor um conjunto de informações acerca dos dados a fim de que a pesquisadora passa tomar passos adiante ou atrás no processo de análise. Igualmente, ela fornece um sumário descritivo. Segundo (Pearson 2018), a análise exploratória dos dados coletados sobre as reclamações ao STF busca responder as seguintes questões: Quantos registros a base de dados sobre reclamações contêm? (Isto é, quantas decisões do STF sobre reclamações estão sendo analisadas) Quantas colunas, i.e, variáveis, estão incluídas em cada um dos registros? Que tipo de variáveis são essas? (i.e. numéricas, categóricas, contínuas, discretas?) Esses dados foram todos observados? (i.e. há dados faltantes, há outliers?) As variáveis incluídas na base são aquelas que nós realmente estávamos esperando? Os valores contidos nas variáveis são consistentes?, i.e. número de categorias, categorias corretas etc, ? As associações entre as variáveis são aquelas que esperávamos? 7.1 Por exemplo, podemos esperar que o CPC 2015 elevou o número de procedência dos pedidos? 7.2 Podemos esperar diferenças entre os ministros quanto ao número de casos procedentes ou não? É importante destacar que a análise exploratória é útil para verificar a associação entre as variáveis, particularmente entre as variáveis preditoras e a variável resposta. Inclusive iremos realizar alguns testes de associação, e.g, chi-quadrado, de força dessas associações (WOE) e mesmo capacidade preditiva das variáveis explicativas. No entanto, é fundamental tomar em conta que os testes de associação e de significância, tal como o teste do chi-quadrado e o t-test, não informam nada sobre o efeito marginal de cada uma das variáveis explicativas sobre a variável resposta. Em pesquisas experimentais, isso é perfeitamente possível porque o pesquisador possui controle preciso sobre os fatores que causam ou modificam o resultado obtido. Por sua vez, as pesquisas em ciências sociais se caracterizam por serem observacionais e a pesquisadora não possui controle apriorístico sobre o efeito de uma variável sobre a outra. Ela precisa precisa considerar outros fatores que afetam o resultado para assim isolar o efeito de cada uma das variáveis explicativas sobre o resultado(Silva 2018). Na pesquisa em tela, estamos diante de dados observacionais. O esforço é dirigido em identificar todos os possíveis fatores que influenciam a resposta judicial ao pedido. Nesse sentido, os testes de associação bivariados são inadequados porque irão superdimensionar o efeito de uma variável sobre a outra. A tarefa, a qual será executada na próxima seção, será de isolar o efeito de cada uma das variáveis explicativas sobre a variável resposta: decisão judicial. Com efeito, podemos supor que o ministro A julgará diferentemente o pedido de reclamação quando se tratar de uma alegada violação a uma súmula do STF do que quando se tratar de uma violaçã a uma decisão inter partes ou que uma reclamação contra decisão da justiça do trabalho tem maior probabilidade de ter uma resposta favorável quando o ministro é fulano do que quando este é beltrano. Esse tipo de controle somente é posssível realizar por meio das técnicas de regressão, pois o objetivo destas é justamente isolar o efeito de cada uma das variáveis sobre os resultado. References "],
["5-1-estatisticas-das-variaveis.html", "5.1 Estatísticas das variáveis", " 5.1 Estatísticas das variáveis rcl_dataset &lt;- readRDS(&quot;../data/rcl_dataset.rds&quot;) ( descricao1 &lt;- ExpData(rcl_dataset,1) %&gt;% setNames(c(&quot;Descrições&quot;,&quot;Registros&quot;)) ) ( descricao2&lt;-ExpData(rcl_dataset,2) %&gt;% select(-1) %&gt;% setNames(c(&quot;Nome da variável&quot;,&quot;Tipo de variável&quot;,&quot;% dados faltantes&quot;,&quot;No. valores únicos&quot;)) ) ( frequencias &lt;- ExpCTable(rcl_dataset,Target=&quot;decisao&quot;,margin=1,clim=10,nlim=NULL,round=2,bin=NULL,per=T) %&gt;% setNames(c(&quot;Variável&quot;,&quot;Categoria&quot;,&quot;Número&quot;,&quot;decisao:improcedente&quot;,&quot;decisao:procedente&quot;,&quot;TOTAL&quot;)) ) "],
["5-2-valor-da-informacao-e-peso-de-evidencia.html", "5.2 Valor da informação e peso de evidência", " 5.2 Valor da informação e peso de evidência Em análise de respostas binárias, duas medidas muito utilizadas nas análises para concessão de crédito, mas quase desconhecidas nas demais áreas, são o peso da evidência e o valor da informação (WOE e IV nas siglas em inglês). Essas duas medidas são importantes na fase de exploração dos dados porque elas: Levam em conta a contribuição independente de cada variável para o resultado. Detetam relações lineares e não lineares com a veriável resposta Classificam as variáveis em termos de força preditiva “univariada”. Visualize as correlações entre as variáveis preditivas e o resultado binário. Comparam perfeitamente a força de variáveis contínuas e categóricas sem criar variáveis fictícias. Tratam perfeitamente de dados faltantes (missing) sem imputação. Avaliam o poder preditivo dos dados faltantes. WOE e IV são conceitos relacionados e foram gestados na teoria da informação a fim de medir o grau de incerteza envolvido na predição de eventos, dados os diferentes graus de conhecimento sobre as variáveis envolvidas. Em poucas palavras WOE descreve a relação entre uma variável preditiva e a variável binária alvo, no caso a decisão judicial, Por sua vez IV mede a força dessa relação. WOE describes the relationship between a predictive variable and a binary target variable. A tabela a seguir mostra os resultados • Variável – nome da variável • Decisão - Variável resposta (decisão judicial) • classe – classe da variável • out0 – Número de procedentes • out1 – Número de improcedentes • Total – Total de respostas para cada categoria • pe_1 – procedentes / total de procedentes (em percentual) • pe_0 – improcedentes / total de improcedentes (em percentual) • odds – pe_1/pe_0 • woe – Peso da evidência (Weight of Evidence), calculado com o logarítimo natural de odds. • iv – Valor da informação (Information Value) - woe * (pe_0 – pe_1) Para facilitar a interpretação dos resultados, tome-se em consideração os seguintes critérios: Se o IV é menor que 0.03 então o poder preditivo é = “Não preditivo” Se o IV está de 0.3 para 0.1 então o poder preditivo é = “Moderadamente preditivo” Se o IV está de 0.1 para 0.3 então o poder preditivo é = “Medianamente preditivo” Se o IV é maior que &gt; 0.3 então o poder preditivo é = “Altamente preditivo” ( stat&lt;-ExpCatStat(rcl_dataset,Target=&quot;decisao&quot;,Label=&quot;Decisões&quot;,result = &quot;Stat&quot;,clim=15,Pclass=&quot;procedente&quot;) ) "],
["5-3-fluxo-dos-processo.html", "5.3 Fluxo dos processo", " 5.3 Fluxo dos processo O gráfico abaixo mostra o fluxo dos processos tomando em conta cada uma das variáveis. Cada linha, roxa ou laranja, representa uma reclamação. A cor laranja representa o conjunto dos pedidos procedentes, a cor roxa representa o conjunto dos pedidos improcedentes. As variáveis foram ordenadas conforme a frequência com que decidem favoravelmente ou desfavoravelmete. Da visualização, é possível observar que as decisões colegiadas, i.e. decisões dos agravos, são maiormente improcedentes. Com efeito, do total, 1884 decisões colegiadas foram improcedentes e apenas 51 foram procedentes. Uma vez que essas decisão são regularmente proferidas ante de uma irresignação contra uma decisão monocrática, é possível afirmar com tranquilidade nesse caso, e não precisaríamos de qualquer teste estatístico para concluir isso, que as decisões colegiadas assumem papel nitidamente homologatório das decisões monocráticas. Por outro lado, os ministros Alexandre de Moraes, Gilmar Mendes e Marco Aurélio lideram entre aqueles que mais concedem pedidos. Houve mais concessões após o CPC 2015 e a justiça do trabalho é aparentemente a mais resistente. Por sua vez, as reclamações contra supostas violações de súmulas não são tão bem sucedidas quanto as reclamações contra supostas violações de recursos extraordinários e decisões interpartes. knitr::include_graphics(&quot;https://apps.consudata.com.br/shiny/gg_alluvial.png&quot;) A tabela abaixo mostra as diferenças entre os órgãos julgadores em números "]
]
